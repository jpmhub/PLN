{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a5612cd",
   "metadata": {},
   "source": [
    "Juan Pablo Márquez 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49955f85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'popular'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package cmudict to\n",
      "[nltk_data]    |     C:\\Users\\anton\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package cmudict is already up-to-date!\n",
      "[nltk_data]    | Downloading package gazetteers to\n",
      "[nltk_data]    |     C:\\Users\\anton\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
      "[nltk_data]    | Downloading package genesis to\n",
      "[nltk_data]    |     C:\\Users\\anton\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package genesis is already up-to-date!\n",
      "[nltk_data]    | Downloading package gutenberg to\n",
      "[nltk_data]    |     C:\\Users\\anton\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
      "[nltk_data]    | Downloading package inaugural to\n",
      "[nltk_data]    |     C:\\Users\\anton\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package inaugural is already up-to-date!\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     C:\\Users\\anton\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
      "[nltk_data]    | Downloading package names to\n",
      "[nltk_data]    |     C:\\Users\\anton\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package names is already up-to-date!\n",
      "[nltk_data]    | Downloading package shakespeare to\n",
      "[nltk_data]    |     C:\\Users\\anton\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
      "[nltk_data]    | Downloading package stopwords to\n",
      "[nltk_data]    |     C:\\Users\\anton\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package stopwords is already up-to-date!\n",
      "[nltk_data]    | Downloading package treebank to\n",
      "[nltk_data]    |     C:\\Users\\anton\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     C:\\Users\\anton\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw to\n",
      "[nltk_data]    |     C:\\Users\\anton\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw-1.4 to\n",
      "[nltk_data]    |     C:\\Users\\anton\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet to\n",
      "[nltk_data]    |     C:\\Users\\anton\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet2021 to\n",
      "[nltk_data]    |     C:\\Users\\anton\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet2021 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet31 to\n",
      "[nltk_data]    |     C:\\Users\\anton\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet31 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet_ic to\n",
      "[nltk_data]    |     C:\\Users\\anton\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
      "[nltk_data]    | Downloading package words to\n",
      "[nltk_data]    |     C:\\Users\\anton\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package words is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     C:\\Users\\anton\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt to\n",
      "[nltk_data]    |     C:\\Users\\anton\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package punkt is already up-to-date!\n",
      "[nltk_data]    | Downloading package snowball_data to\n",
      "[nltk_data]    |     C:\\Users\\anton\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     C:\\Users\\anton\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection popular\n"
     ]
    }
   ],
   "source": [
    "#emprarem la llibreria NLTK, concretament el tokenitzador a nivell de paraula 'word_tokenize'.\n",
    "import nltk\n",
    "nltk.download(\"popular\")\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2496384a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Trump', 'NNP'), ('saw', 'VBD'), ('the', 'DT'), ('yellow', 'JJ'), ('dog', 'NN'), ('and', 'CC'), ('the', 'DT'), ('cat', 'NN'), ('was', 'VBD'), ('of', 'IN'), ('that', 'DT'), ('Florida', 'NNP')]\n",
      "(S\n",
      "  (PERSON Trump/NNP)\n",
      "  saw/VBD\n",
      "  the/DT\n",
      "  yellow/JJ\n",
      "  dog/NN\n",
      "  and/CC\n",
      "  the/DT\n",
      "  cat/NN\n",
      "  was/VBD\n",
      "  of/IN\n",
      "  that/DT\n",
      "  (GPE Florida/NNP))\n"
     ]
    }
   ],
   "source": [
    "sentence = \"Trump saw the yellow dog and the cat was of that Florida\"\n",
    "tokens = nltk.word_tokenize(sentence) # Extreim els tokens\n",
    "tagged = nltk.pos_tag(tokens) # assignam el POS de cada token\n",
    "print(tagged) \n",
    "entitats = nltk.chunk.ne_chunk(tagged) # anàlisi sintàctic bàsic a partir d'unes dades\n",
    "# preentrenades que es poden emprar a través del mètode ne_chunk. Aquest mètode fragmenta frase a frase\n",
    "# i detecta només PERSONA, UBICACIÓ I ORGANITZACIÓ.\n",
    "#'S' faria referència a la frase i 'GPE' indicaria que ha trobat una entitat Geo Politica...\n",
    "print(entitats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22041c42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in c:\\users\\anton\\anaconda3\\lib\\site-packages (3.2.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from spacy) (1.20.3)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from spacy) (8.0.13)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from spacy) (2.0.6)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from spacy) (4.62.3)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from spacy) (3.0.6)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from spacy) (2.26.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from spacy) (21.0)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from spacy) (1.0.1)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from spacy) (0.6.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from spacy) (2.4.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\anton\\anaconda3\\lib\\site-packages (from spacy) (58.0.4)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from spacy) (2.11.3)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from spacy) (0.7.5)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from spacy) (0.9.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from spacy) (2.0.6)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from spacy) (0.4.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from spacy) (3.0.8)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from spacy) (1.8.2)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from spacy) (1.0.6)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy) (3.0.4)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from pathy>=0.3.5->spacy) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy) (3.10.0.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.2)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2021.10.8)\n",
      "Requirement already satisfied: colorama in c:\\users\\anton\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from typer<0.5.0,>=0.3.0->spacy) (8.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from jinja2->spacy) (1.1.1)\n",
      "Collecting en-core-web-sm==3.2.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.2.0/en_core_web_sm-3.2.0-py3-none-any.whl (13.9 MB)\n",
      "Requirement already satisfied: spacy<3.3.0,>=3.2.0 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from en-core-web-sm==3.2.0) (3.2.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.3.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.0.6)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.4.2)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.0.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.0.6)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (4.62.3)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.7.5)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.0.6)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.26.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.8.2)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.4.0)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.6.1)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (8.0.13)\n",
      "Requirement already satisfied: setuptools in c:\\users\\anton\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (58.0.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (21.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.0.6)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.11.3)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.9.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.20.3)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.0.8)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.0.4)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from pathy>=0.3.5->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.10.0.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.2)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\anton\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.4.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from typer<0.5.0,>=0.3.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (8.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from jinja2->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.1.1)\n",
      "[+] Download and installation successful\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "# instal·lam spacy que és una llibreria amb eines pel PLN\n",
    "!pip install -U spacy\n",
    "# en aquest cas descarregarem el paquet anglès 'en_core_web_sm'\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a475bdaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"a75959ef559844198b1604df68db7c34-0\" class=\"displacy\" width=\"1450\" height=\"399.5\" direction=\"ltr\" style=\"max-width: none; height: 399.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">The</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">refugees</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">in</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">Afghanistan</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">escaped</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">mainly</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">ADV</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">towards</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">Madrid.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-a75959ef559844198b1604df68db7c34-0-0\" stroke-width=\"2px\" d=\"M70,264.5 C70,177.0 215.0,177.0 215.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-a75959ef559844198b1604df68db7c34-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,266.5 L62,254.5 78,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-a75959ef559844198b1604df68db7c34-0-1\" stroke-width=\"2px\" d=\"M245,264.5 C245,2.0 750.0,2.0 750.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-a75959ef559844198b1604df68db7c34-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,266.5 L237,254.5 253,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-a75959ef559844198b1604df68db7c34-0-2\" stroke-width=\"2px\" d=\"M245,264.5 C245,177.0 390.0,177.0 390.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-a75959ef559844198b1604df68db7c34-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M390.0,266.5 L398.0,254.5 382.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-a75959ef559844198b1604df68db7c34-0-3\" stroke-width=\"2px\" d=\"M420,264.5 C420,177.0 565.0,177.0 565.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-a75959ef559844198b1604df68db7c34-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M565.0,266.5 L573.0,254.5 557.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-a75959ef559844198b1604df68db7c34-0-4\" stroke-width=\"2px\" d=\"M770,264.5 C770,177.0 915.0,177.0 915.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-a75959ef559844198b1604df68db7c34-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M915.0,266.5 L923.0,254.5 907.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-a75959ef559844198b1604df68db7c34-0-5\" stroke-width=\"2px\" d=\"M770,264.5 C770,89.5 1095.0,89.5 1095.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-a75959ef559844198b1604df68db7c34-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1095.0,266.5 L1103.0,254.5 1087.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-a75959ef559844198b1604df68db7c34-0-6\" stroke-width=\"2px\" d=\"M1120,264.5 C1120,177.0 1265.0,177.0 1265.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-a75959ef559844198b1604df68db7c34-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1265.0,266.5 L1273.0,254.5 1257.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#importam aquesta llibreria que serveix pel tratament de PLN en diferents idiomes.\n",
    "# displacy és un visualitzador de la llibreria spacy. En aquest cas ens permetra veure l'arbre sintàctic.\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "nlp = spacy.load(\"en_core_web_sm\") \n",
    "# 'en_core_web_sm' és un paquet de llengua anglesa pensada per textes web (blocs, notícies,comentaris...)\n",
    "# més informació sobre els paquets d'idiomes a 'https://spacy.io/models'\n",
    "texte = \"The refugees in Afghanistan escaped mainly towards Madrid.\"\n",
    "doc = nlp(texte)\n",
    "displacy.render(doc, style=\"dep\", jupyter=True) # esquema anàlisi sintàctic. Empram visualitzador\n",
    "# displacy i el mètode 'render' per  notebooks de Jupyter.\n",
    "# 'dep' per només etiquetar.\n",
    "#'jupyter=True' indicaria que treballem amb aquest notebook i en cas d'exportar-ho a un fitxer es faria amb HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8204efd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ca-core-news-sm==3.2.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/ca_core_news_sm-3.2.0/ca_core_news_sm-3.2.0-py3-none-any.whl (20.7 MB)\n",
      "Requirement already satisfied: spacy<3.3.0,>=3.2.0 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from ca-core-news-sm==3.2.0) (3.2.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->ca-core-news-sm==3.2.0) (3.0.8)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->ca-core-news-sm==3.2.0) (8.0.13)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->ca-core-news-sm==3.2.0) (0.6.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->ca-core-news-sm==3.2.0) (3.3.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->ca-core-news-sm==3.2.0) (2.0.6)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->ca-core-news-sm==3.2.0) (21.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\anton\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->ca-core-news-sm==3.2.0) (58.0.4)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->ca-core-news-sm==3.2.0) (1.8.2)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->ca-core-news-sm==3.2.0) (1.0.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->ca-core-news-sm==3.2.0) (3.0.6)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->ca-core-news-sm==3.2.0) (0.9.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->ca-core-news-sm==3.2.0) (2.26.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->ca-core-news-sm==3.2.0) (2.11.3)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->ca-core-news-sm==3.2.0) (2.0.6)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->ca-core-news-sm==3.2.0) (0.7.5)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->ca-core-news-sm==3.2.0) (2.4.2)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->ca-core-news-sm==3.2.0) (0.4.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->ca-core-news-sm==3.2.0) (4.62.3)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->ca-core-news-sm==3.2.0) (1.0.6)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->ca-core-news-sm==3.2.0) (1.20.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy<3.3.0,>=3.2.0->ca-core-news-sm==3.2.0) (3.0.4)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from pathy>=0.3.5->spacy<3.3.0,>=3.2.0->ca-core-news-sm==3.2.0) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.3.0,>=3.2.0->ca-core-news-sm==3.2.0) (3.10.0.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->ca-core-news-sm==3.2.0) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->ca-core-news-sm==3.2.0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->ca-core-news-sm==3.2.0) (3.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->ca-core-news-sm==3.2.0) (1.26.7)\n",
      "Requirement already satisfied: colorama in c:\\users\\anton\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.3.0,>=3.2.0->ca-core-news-sm==3.2.0) (0.4.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from typer<0.5.0,>=0.3.0->spacy<3.3.0,>=3.2.0->ca-core-news-sm==3.2.0) (8.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\anton\\anaconda3\\lib\\site-packages (from jinja2->spacy<3.3.0,>=3.2.0->ca-core-news-sm==3.2.0) (1.1.1)\n",
      "[+] Download and installation successful\n",
      "You can now load the package via spacy.load('ca_core_news_sm')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"ca\" id=\"cd38c42237bd43a59c63ecea20fa3ae0-0\" class=\"displacy\" width=\"750\" height=\"399.5\" direction=\"ltr\" style=\"max-width: none; height: 399.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Això</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">és</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">una</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">frase</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-cd38c42237bd43a59c63ecea20fa3ae0-0-0\" stroke-width=\"2px\" d=\"M70,264.5 C70,2.0 575.0,2.0 575.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-cd38c42237bd43a59c63ecea20fa3ae0-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,266.5 L62,254.5 78,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-cd38c42237bd43a59c63ecea20fa3ae0-0-1\" stroke-width=\"2px\" d=\"M245,264.5 C245,89.5 570.0,89.5 570.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-cd38c42237bd43a59c63ecea20fa3ae0-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">cop</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,266.5 L237,254.5 253,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-cd38c42237bd43a59c63ecea20fa3ae0-0-2\" stroke-width=\"2px\" d=\"M420,264.5 C420,177.0 565.0,177.0 565.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-cd38c42237bd43a59c63ecea20fa3ae0-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M420,266.5 L412,254.5 428,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# en aquest cas descarregam el paquet en català\n",
    "!python -m spacy download ca_core_news_sm\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "nlp = spacy.load(\"ca_core_news_sm\")\n",
    "doc = nlp(\"Això és una frase\")\n",
    "displacy.render(doc, style=\"dep\", jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "031bd31f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\anton\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['adventure', 'belles_lettres', 'editorial', 'fiction', 'government', 'hobbies', 'humor', 'learned', 'lore', 'mystery', 'news', 'religion', 'reviews', 'romance', 'science_fiction']\n",
      "57340\n",
      "Rendiment dades entrenament: \n",
      "0.9349006503968017\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('the', 'AT'),\n",
       " ('human', 'NN'),\n",
       " ('race', 'NN'),\n",
       " ('is', 'BEZ'),\n",
       " ('expected', 'VBN'),\n",
       " ('to', 'TO'),\n",
       " ('become', 'VBN'),\n",
       " ('extinct', None),\n",
       " ('tomorrow', 'NR')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import tokenize\n",
    "# El Corpus Brown de NLTK va ser el primer gran corpus orientat a tasques de PLN. \n",
    "# la seva principal característica és que la informació està organitzada per gèneres\n",
    "nltk.download(\"brown\")\n",
    "from nltk.corpus import brown\n",
    "from nltk import tag\n",
    "print(brown.categories()) # gèneres que conté aquest corpus\n",
    "print(len(brown.tagged_sents())) # nombre total de frases\n",
    "# 'tagged_sents' és una llista de frases del corpus 'brown'. Cada frase és una llista de parelles(paraula, etiqueta). \n",
    "# també es pot accedir al corpus com una llista plana de paraules etiquetades envers de fer-ho per frases.\n",
    "train_sents = brown.tagged_sents(categories=\"news\") \n",
    "# 'train_sents' contendrà frases de la categoria 'news' com a dades d'entrenament\n",
    "unigram_tagger = tag.UnigramTagger(train_sents)\n",
    "# UnigramTagger troba l'etiqueta més probable per a cada paraula de la llista d'entrenament. Això no és 100% fiable.\n",
    "# hi pot haver casos que analitzar paraula a paraula no sigui convenient, p.e. el terme 'riu' podria ser una nom o bé un verb\n",
    "# Si en lloc de calcular a nivell de paraula (unigrames), ho fem a nivell de dues (bigrama) o tres paraules (trigrama), podríem tenir millors resultats.\n",
    "# després utilitza aquesta informació per assignar etiquetes a nous tokens.\n",
    "print(\"Rendiment dades entrenament: \")\n",
    "print(unigram_tagger.evaluate(train_sents))\n",
    "# obtenim aprox un 93'5% de fiabilitat en els resultats.\n",
    "text = \"the human race is expected to become extinct tomorrow\"\n",
    "# 'race' podria ser una carrera i una raça. Hauríem de veure si ho interpreta bé emprant unigrames.\n",
    "tokens = list(tokenize.word_tokenize(text)) #obtenim els tokens\n",
    "list(unigram_tagger.tag(tokens)) # a partir de les dades d'entrenament passem el text que volem obtenir les etiquetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ff8c880",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package cess_esp to\n",
      "[nltk_data]     C:\\Users\\anton\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package cess_esp is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rendiment dades entranament: \n",
      "0.9573762494420975\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('La', 'da0fs0'),\n",
       " ('casa', 'ncfs000'),\n",
       " ('de', 'sps00'),\n",
       " ('papel', 'ncms000'),\n",
       " ('es', 'vsip3s0'),\n",
       " ('una', 'di0fs0'),\n",
       " ('serie', 'ncfs000'),\n",
       " ('muy', 'rg'),\n",
       " ('nueva', 'aq0fs0')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exemple emprant el corpus 'cess_esp' del castellà de la llibreria NLTK. Està format a partir de notícies.\n",
    "nltk.download('cess_esp')\n",
    "from nltk.corpus import cess_esp\n",
    "# obtenim les dades d'entrenament.\n",
    "train_sents = cess_esp.tagged_sents()\n",
    "# UnigramTagger trobarà l'etiqueta més probable per a cada paraula de la llista d'entrenament.\n",
    "unigram_tagger = tag.UnigramTagger(train_sents)  # BigramTagger, TrigramTagger\n",
    "print(\"Rendiment dades entranament: \")\n",
    "print(unigram_tagger.evaluate(train_sents))\n",
    "texte = \"La casa de papel es una serie muy nueva\"\n",
    "tokens = list(tokenize.word_tokenize(texte)) # obtenim els tokens de la frase que volem analitzar.\n",
    "list(unigram_tagger.tag(tokens)) # llistam els tokens juntament amb la seva funció."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ab70ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixa't que les etiquetes que són diferents a les etiquetes que havíem vist en anglès. \n",
    "# El castellà és una llengua amb una morfologia més rica\n",
    "# si volem reflectir el gènere i el número dels adjectius, per exemple, no ens val amb etiquetar els adjectius \n",
    "# amb una simple JJ.\n",
    "\n",
    "#  ncfs000: nom comú femení singular\n",
    "#  da0ms0: determinant article masculí singular\n",
    "#  ncms000: nom comú masculí singular\n",
    "#  aq0cs0: adjectiu qualificatiu comú singular\n",
    "#  np00000: nom propi\n",
    "#  sps00: preposició\n",
    "#  vmis3s0: verb principal indicatiu passat 3a persona del singular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b83b0c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exemple senzill com generar arbre amb la funció draw que analitza sintàcticament la primera frase del corpus espanyol.\n",
    "primera_frase=nltk.corpus.cess_esp.parsed_sents()[0]\n",
    "primera_frase.draw()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
