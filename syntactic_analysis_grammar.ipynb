{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44bf107a",
   "metadata": {},
   "source": [
    "Juan Pablo Márquez 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca87aed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP Mary/NN)\n",
      "  saw/VBD\n",
      "  (CLAUSE\n",
      "    (NP the/DT cat/NN)\n",
      "    (VP sit/VB (PP on/IN (NP the/DT mat/NN)))))\n"
     ]
    }
   ],
   "source": [
    "#EXEMPLE SENZILL DE COM ES POT DEFINIR UNA GRAMÀTICA I DESPRÉS ANALITZAR TEXTOS\n",
    "import nltk\n",
    "# definin la nostra gramàtica amb una expressió regular\n",
    "# NP=sintagma nominal PP=sintagma preposicional  VP=sintagma verbal\n",
    "# recorda que el símbol '$' marca el final de la cadena\n",
    "# el '.' indica qualsevol caracter excepte una nova linea\n",
    "# el '$' indica el final de linea\n",
    "# el '*' indica 0 o més repeticions del precedent (p.e ab* podria ser 'a', 'ab','abb'...)\n",
    "# el '+' indica 1 o més repeticions del precedent (p.e ab+ podria ser 'ab','abb',...)\n",
    "# el '?' indica 0 o 1 repeticions del precedent (p.e ab? podria ser 'a' o 'ab')\n",
    "grammar = r\"\"\"\n",
    "    NP: {<DT|JJ|NN.*>+}          # Chunk sequences of DT, JJ, NN (determinant o adjectiu o nom una o més vegades)\n",
    "    PP: {<IN><NP>}               # Chunk prepositions followed by NP (preposicio + sintagma nominal)\n",
    "    VP: {<VB.*><NP|PP|CLAUSE>+$} # Chunk verbs and their arguments (verb seguit on no d'un sintagma nominal o preposicional o...)\n",
    "    CLAUSE: {<NP><VP>}           # Chunk NP, VP (sintagma nominal + sintagma verbal)\n",
    "\"\"\"\n",
    "# passam a l'analitzador sintàctic les regles de la nostra gramàtica.\n",
    "cp = nltk.RegexpParser(grammar)\n",
    "# es definirà la frase a analitzar havent passat l'anàlisi lèxic. \n",
    "sentence = [(\"Mary\", \"NN\"), (\"saw\", \"VBD\"), (\"the\", \"DT\"), (\"cat\", \"NN\"),\n",
    "    (\"sit\", \"VB\"), (\"on\", \"IN\"), (\"the\", \"DT\"), (\"mat\", \"NN\")]\n",
    "# passem el parser per analitzar la nostra frase\n",
    "analisi=cp.parse(sentence)\n",
    "print(analisi)\n",
    "analisi.draw() # imprimim arbre resultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "777cd964",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package conll2000 to\n",
      "[nltk_data]     C:\\Users\\anton\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package conll2000 is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChunkParse score:\n",
      "    IOB Accuracy:  44.1%%\n",
      "    Precision:      0.0%%\n",
      "    Recall:         0.0%%\n",
      "    F-Measure:      0.0%%\n"
     ]
    }
   ],
   "source": [
    "#EINES AVALUACIÓ DE PATRONS A PARTIR DEL CORPUS CONLL 2000 (idioma anglès)\n",
    "# aquest corpus és ideal per avaluar gramàtiques perquè conté frases analitzades sintàcticament \n",
    "# emprarem el paquet d'entrenament d'aquest corpus 'train.txt' i cercarem sintagmes nominals 'NP'\n",
    "nltk.download(\"conll2000\")\n",
    "from nltk.corpus import conll2000\n",
    "cp=nltk.RegexpParser(\"\") #li passem una gramàtica buida i ens fixarem en els resultats\n",
    "test_sents=conll2000.chunked_sents(\"train.txt\",chunk_types=['NP'])\n",
    "# avaluarem quants 'NP' que hi ha al fitxer d'entrenament coincideixen amb el nostre chunk buit \"\"\n",
    "print(cp.evaluate(test_sents))\n",
    "# la precisió és del 0% ja que no ha detectat cap 'NP'\n",
    "# la Accuracy és del 44%, tot i que no ha detectat cap 'NP', perquè també té en compte les dades que no tenien 'NP'\n",
    "# Recall indica el nombre de 'NP' classificats correctament respecte al nombre total de NP\n",
    "# F-measure és una combinació de precision i recall per a poder tenir un únic indicador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79bee240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChunkParse score:\n",
      "    IOB Accuracy:  73.9%%\n",
      "    Precision:     37.6%%\n",
      "    Recall:        34.9%%\n",
      "    F-Measure:     36.2%%\n"
     ]
    }
   ],
   "source": [
    "#EINES AVALUACIÓ DE PATRONS A PARTIR DEL CORPUS CONLL 2000 (idioma anglès)\n",
    "# emprarem el paquet d'entrenament d'aquest corpus 'train.txt' i cercarem sintagmes nominals 'NP'\n",
    "cp=nltk.RegexpParser(grammar) #li passem la gramàtica definida al princi del document\n",
    "# amb el paquet d'entrenament cercam els 'NP' que hi ha\n",
    "test_sents=conll2000.chunked_sents(\"train.txt\",chunk_types=['NP'])\n",
    "# avaluarem quants 'NP' que hi ha al fitxer d'entrenament coincideixen amb el 'NP' definit a la nostra gramàtica\n",
    "# així podrem saber si la nostra gramàtica és bona per identificar patrons 'NP'\n",
    "print(cp.evaluate(test_sents))\n",
    "# evidentment els resultats no són molt bons perquè la nostra gramàtica deixa de tenir en compte molts de tipus 'NP'\n",
    "# fixeu-vos que accuracy és més alta, ja que té en compte tot allò que està fora de NP i que es classifica correctament"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "235e9585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChunkParse score:\n",
      "    IOB Accuracy:  83.2%%\n",
      "    Precision:     65.2%%\n",
      "    Recall:        67.2%%\n",
      "    F-Measure:     66.2%%\n"
     ]
    }
   ],
   "source": [
    "# anem a millorar el nostre patró 'NP' perquè inclogui també els pronoms personals 'PRP' i els possessius 'PRP$'\n",
    "gramatica=r\"NP: {<DT|JJ|NN.*>+ | <PRP.*>}\"\n",
    "cp=nltk.RegexpParser(gramatica) #li passem la gramàtica definida al princi del document\n",
    "test_sents=conll2000.chunked_sents(\"train.txt\",chunk_types=['NP'])\n",
    "print(cp.evaluate(test_sents))\n",
    "# fixau-vos com milloren les dades!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12300837",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
